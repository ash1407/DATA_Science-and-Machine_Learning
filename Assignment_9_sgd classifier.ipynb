{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea78c00-b077-4b72-88cf-b2a68326505c"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONY1YiDq7jD"
      },
      "source": [
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ad7507-e62a-44fa-eb56-8a5a0e6e86e0"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26775106-ebd9-4cfc-9584-d867c6080150"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ffdef2-7d61-4f79-c5ed-c7eff59bcc89"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
            "Total training time: 0.13 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
            "Total training time: 0.14 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
            "Total training time: 0.15 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
            "Total training time: 0.16 seconds.\n",
            "Convergence after 14 epochs took 0.16 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50008d03-a580-454f-d7fa-896c50973107"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
              "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
              "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
              " (1, 15),\n",
              " array([-1.30580538]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7UmSpTC2eCv"
      },
      "source": [
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "##Splitting train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)\n",
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_-UvDmVlPFB",
        "outputId": "3dfb4a3d-1c9c-4995-8ccb-2c70dbaa46a6"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (dim,1) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    w = np.zeros_like(X_train[0])\n",
        "    b = 0\n",
        "    return w,b"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724e3c99-508b-4b1d-ff1f-1db7ea21c1f4"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ffa741-62fd-485b-fcb8-5b066a97ec3a"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e53ecef-7aa1-4621-d4e0-1769845f6e0a"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "    sum = 0\n",
        "    for i in range(len(y_true)):\n",
        "        sum += (y_true[i] * np.log10(y_pred[i])) + ((1 - y_true[i]) * np.log10(1 - y_pred[i]))\n",
        "    loss = -1 * (1 / len(y_true)) * sum\n",
        "    return loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8581b86f-12ed-405d-b37c-6172ac8f1290"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(loss==0.07644900402910389)\n",
        "  return True\n",
        "true=[1,1,0,1,0]\n",
        "pred=[0.9,0.8,0.1,0.8,0.2]\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw = x * (y - sigmoid(np.dot(w,x) + b) - (alpha / N) * w)\n",
        "    return dw"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4378e8ea-67b6-41c4-b2af-de9dc32de948"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        "def gradient_db(x,y,w,b):\n",
        "    '''In this function, we will compute gradient w.r.to b '''\n",
        "    db = y - sigmoid(np.dot(w,x) + b)\n",
        "    return db"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c3ee20-80f8-48a1-ecd2-f738127b18df"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    #Here eta0 is learning rate\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    w, b = initialize_weights(X_train[0])\n",
        "    print(w)\n",
        "    print(b)\n",
        "    \n",
        "    for i in range(epochs):\n",
        "        train_pred = []\n",
        "        test_pred = []\n",
        "        for j in range(N):\n",
        "            dw = gradient_dw(X_train[j],y_train[j],w,b,alpha,N)\n",
        "            db = gradient_db(X_train[j],y_train[j],w,b)\n",
        "            w = w + (eta0 * dw)\n",
        "            b = b + (eta0 * db)\n",
        "        for val in range(N):\n",
        "            train_pred.append(sigmoid(np.dot(w, X_train[val]) + b))\n",
        "            \n",
        "        loss1 = logloss(y_train, train_pred)\n",
        "        train_loss.append(loss1)\n",
        "            \n",
        "        for val in range(len(X_test)):\n",
        "            test_pred.append(sigmoid(np.dot(w, X_test[val]) + b))\n",
        "            \n",
        "        loss2 = logloss(y_test, test_pred)\n",
        "        test_loss.append(loss2)\n",
        "    return w,b,train_loss,test_loss     "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1bae020-3d92-401f-a03b-d872a3bd28a3"
      },
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=15\n",
        "w,b,train_log_loss,test_log_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)\n",
        "   "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8Rs9rfEZ1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b7898f-939f-46e3-90ff-2dd00d7a5334"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.01475441,  0.01493819, -0.00227911,  0.00670557, -0.00641397,\n",
              "          0.01189451, -0.00725789,  0.00180162,  0.00978707,  0.00360842,\n",
              "          0.00457527,  0.00349702,  0.00054823,  0.00292801,  0.00056488]]),\n",
              " array([-0.00611701]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O6GrRt7UeCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f690feca-0299-4754-aa57-fc0aaf0ed1fd"
      },
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.90482624  0.64656181 -0.07822055  0.63777664 -0.39075772  0.94424694\n",
            " -0.90299309 -0.0716036   0.41570124  0.42360752  0.2517967   0.05395901\n",
            " -0.08823164  0.54374453  0.06700376]\n",
            "-1.3119223867184169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3055df-12a1-42d1-ebd7-e43fc71a30ef"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9506666666666667\n",
            "0.94768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k28U1xDsLIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cac331-82c4-4b3d-dd98-52f2c9455cb5"
      },
      "source": [
        "print(train_log_loss)\n",
        "print(test_log_loss)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20729781768555863, 0.18556210114210764, 0.17659652051133365, 0.1720128945783102, 0.16938000845565493, 0.16775336534502724, 0.16669776257314284, 0.16598837461497834, 0.16549918190509716, 0.16515513910536048, 0.1649094426343844, 0.1647318308366498, 0.16460216936736333, 0.16450674963696027, 0.16443606110787143]\n",
            "[0.20722219765639838, 0.18565259407762202, 0.17682567687044423, 0.1723532481070215, 0.1698100980186653, 0.16825663459379128, 0.16726128852995398, 0.1666019295079757, 0.16615457088217908, 0.16584572638431588, 0.16562980512109732, 0.16547750011239434, 0.16536943657077657, 0.16529251605486997, 0.16523772251217042]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMokBfs3-2PY"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "epoch = [i for i in range(1,16,1)]\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "tSSypVOj0rb_",
        "outputId": "32f3755f-dce7-4cc7-e689-f412bb4fd59f"
      },
      "source": [
        "plt.plot(epoch,train_log_loss, label='train_log_loss')\n",
        "plt.plot(epoch,test_log_loss, label='test_log_loss')\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff06e3c0290>]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpS6OKDH-ize",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "5a3775e2-4ff6-4aef-c852-3a658a65f675"
      },
      "source": [
        "plt.xlabel(\"epoch number\")\n",
        "plt.ylabel(\"log loss\")\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'log loss')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQILgwl2_yxc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "da72e08a-c82a-4f2d-a42f-2308de85dd5b"
      },
      "source": [
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
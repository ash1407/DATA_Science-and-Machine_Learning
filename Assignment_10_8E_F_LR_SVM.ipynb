{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of 8E&F_LR_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HExLQrE4ZxR"
      },
      "source": [
        "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LuKrFzC4ZxV"
      },
      "source": [
        "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wES-wWN4ZxX"
      },
      "source": [
        "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
        "\n",
        "Check the documentation for better understanding of these attributes: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
        "\n",
        "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
        "\n",
        "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
        "\n",
        "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
        "\n",
        "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
        "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
        "\n",
        "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
        "\n",
        "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z830CfMk4Zxa"
      },
      "source": [
        "## Task E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuBxHiCQ4Zxc"
      },
      "source": [
        "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
        "\n",
        "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
        "\n",
        "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCgMNEvI4Zxf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUNIqCe4Zxn"
      },
      "source": [
        "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHie1zqH4Zxt"
      },
      "source": [
        "### Pseudo code\n",
        "\n",
        "clf = SVC(gamma=0.001, C=100.)<br>\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
        "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
        "    \n",
        "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
        "\n",
        "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h43kDT3M41u5"
      },
      "source": [
        "# you can write your code here.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Train, X_test, Y_Train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
        "X_train, X_cv, Y_train, Y_cv = train_test_split(X_Train, Y_Train, test_size = 0.2, random_state = 52, stratify = Y_Train)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSlAyoVzkDDH",
        "outputId": "28e31bb8-39d2-42c6-e42a-3d9d37f02174"
      },
      "source": [
        "clf = SVC(gamma=0.001,C=100, kernel=\"rbf\")\n",
        "clf.fit(X_Train,Y_Train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0jrJeJLkazK"
      },
      "source": [
        "def decision_function(x_cv): #For all Clf.X all the X has been taken from SK_learn SVC documentation\n",
        "    alphas = clf.dual_coef_[0] #https://stats.stackexchange.com/questions/239008/rbf-kernel-algorithm-python\n",
        "                                #https://stats.stackexchange.com/questions/14876/interpreting-distance-from-hyperplane-in-svm\n",
        "    decision_function = []\n",
        "    for Xq in x_cv:\n",
        "        sum = clf.intercept_[0]\n",
        "        for i,support_vecctors in enumerate(clf.support_vectors_):\n",
        "            norm = np.linalg.norm(support_vecctors - Xq)**2 #Calucation ||xi_xq||**\n",
        "            kernel = np.exp(-0.001*norm) # exp{-gamma*||xi_xq||**} calculation of K(Xi,Xq)\n",
        "            sum += (alphas[i]*kernel) # the final calulcation.\n",
        "        decision_function.append(sum)\n",
        "        \n",
        "    return np.array(decision_function)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "503JqX7bkfXh",
        "outputId": "f9a516a1-b8bf-47b5-ab2b-0d46c57752ff"
      },
      "source": [
        "F_cv = decision_function(X_cv)\n",
        "print(F_cv)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.40119332e+00 -1.94290277e+00 -2.49282594e+00 -2.67324201e+00\n",
            "  1.56559886e+00 -8.92844364e-01  1.13962667e+00 -8.84786368e-01\n",
            " -1.18058585e+00  1.87493587e+00 -1.80961243e+00  1.83893779e+00\n",
            " -3.48356000e+00  2.73813793e+00  1.57727686e+00  1.85782144e+00\n",
            " -2.25085808e+00  2.02883101e+00  1.95371756e+00 -2.95551796e+00\n",
            " -2.58724213e+00 -2.59408743e+00 -3.06081710e+00 -1.71742794e+00\n",
            "  5.29106822e-01  9.16076188e-02 -2.29257606e+00 -3.39935659e+00\n",
            " -2.09303471e+00 -2.71959808e+00  1.00925838e+00 -1.24158131e+00\n",
            "  2.28945827e+00 -2.22363098e+00  1.66463172e+00 -2.33789835e+00\n",
            "  3.45532575e-01 -3.25826887e+00 -4.89081417e+00  1.31540962e+00\n",
            "  1.45839586e+00  1.65388580e+00  1.60598221e+00 -1.79225650e+00\n",
            " -1.60905503e+00 -2.90628506e+00  4.79625455e-01  3.17099399e+00\n",
            " -1.42794328e+00  1.93135390e+00 -2.96681350e-01 -1.11781248e+00\n",
            " -2.84461480e+00 -6.24881813e-01 -2.16550536e+00  2.15367171e+00\n",
            "  7.38447638e-02 -3.35109591e+00  6.98859848e-01  1.16724269e-01\n",
            "  2.04312834e-01 -3.38450261e+00 -2.57169616e+00 -3.20284905e+00\n",
            " -2.64980664e+00  5.60456814e-01 -3.79585139e-01 -3.37801439e-01\n",
            " -3.45174697e+00 -2.11905804e+00 -2.15610710e+00 -2.20880162e+00\n",
            " -2.55897231e+00  1.10477458e-01  2.14310769e+00 -2.65849382e+00\n",
            " -2.51577710e+00 -2.23093512e+00 -2.29531124e+00 -4.10417183e+00\n",
            " -3.54092706e+00 -1.23085362e+00  1.40460357e+00  3.93516733e-01\n",
            "  2.07205174e+00 -2.29773691e+00 -1.27614392e+00  4.76494468e-01\n",
            " -2.24767405e+00 -1.56031541e+00 -3.20226394e+00 -4.62577641e+00\n",
            " -2.36187095e+00 -2.58516607e+00 -1.99426353e+00 -1.73462311e+00\n",
            " -4.99802378e-01  1.87391591e+00 -3.04156795e+00 -1.97865561e+00\n",
            " -3.70850476e+00  7.62679361e-01  1.60218314e+00  1.76062987e+00\n",
            "  1.83350184e+00 -3.79689446e+00 -3.29852578e+00 -2.49244136e+00\n",
            " -2.64954359e+00 -1.38618703e+00 -4.30743026e+00 -3.81774320e-01\n",
            " -3.37593555e+00 -2.93165356e+00 -2.01059032e+00 -2.46192484e+00\n",
            "  2.14370864e+00 -2.28482207e+00 -2.30489112e+00  1.67809659e+00\n",
            " -1.05332014e+00 -1.78697463e-01 -2.72735808e+00  1.62214645e+00\n",
            " -4.30651138e-02  1.54857056e+00 -2.55595052e+00 -2.71974786e+00\n",
            "  1.79130711e+00 -1.59335901e+00 -1.05650466e+00  1.26438715e-01\n",
            " -2.19773597e+00 -1.39421310e+00  1.33672277e+00 -2.44206210e+00\n",
            "  1.19823308e-01 -1.82205883e+00 -1.51936205e+00 -2.79372906e+00\n",
            " -7.87711449e-02  9.06626070e-01 -3.10820597e-01  1.19056662e-01\n",
            " -2.62399978e+00 -3.36400171e+00 -3.95097293e+00  2.03379089e+00\n",
            " -2.87226071e+00 -2.09976625e+00 -3.02269035e+00 -5.83045408e-01\n",
            " -2.78072721e+00 -2.22740226e+00 -7.13125716e-01  1.28130238e+00\n",
            " -4.76123123e-01 -3.79469907e+00 -2.69024202e+00 -2.54404207e+00\n",
            "  2.33434614e-01 -3.77830342e+00 -3.26095517e+00  1.21136287e+00\n",
            " -1.64423158e+00 -4.63243782e+00  1.74393147e+00 -3.35554880e+00\n",
            "  1.30832281e+00 -5.01884376e-01  2.03853633e+00  1.33592144e+00\n",
            " -2.07095872e-01 -1.90738379e+00  1.38949622e+00 -8.79367622e-01\n",
            "  9.79038720e-01 -2.13620121e+00 -1.50948541e+00 -5.45580318e+00\n",
            "  8.77485679e-01 -6.67950300e-01 -2.51298323e+00  1.11507897e+00\n",
            " -1.02653413e+00 -2.98176191e+00 -3.35773008e+00  1.82964293e+00\n",
            " -2.25665063e+00 -1.42358997e+00  1.75996717e+00  2.16591196e+00\n",
            " -3.38219597e+00 -2.16362880e+00 -2.70806219e+00  1.72752285e+00\n",
            " -4.54686268e-01 -1.27799452e+00 -7.70629584e-01 -2.33375466e+00\n",
            "  1.36700416e+00 -6.19249586e-01  1.88532611e+00  2.48502950e+00\n",
            "  1.71808716e+00 -3.70623385e+00 -3.27297470e+00 -2.58660031e-01\n",
            " -2.65918463e+00 -2.33409698e+00 -2.12345402e+00 -3.48158414e+00\n",
            " -1.17076114e+00 -2.96309653e+00 -2.48632160e+00 -7.29658490e-01\n",
            " -1.58880755e+00 -3.36271742e+00 -3.11525480e+00  2.56309575e+00\n",
            " -3.20823010e+00  9.32276995e-02 -2.67131106e+00  8.66325352e-01\n",
            "  5.43267096e-01 -5.20083961e+00 -1.92508344e+00 -2.61923327e+00\n",
            " -4.08226719e+00 -4.16336345e+00  3.64185740e-01 -3.61930482e+00\n",
            "  1.79351951e+00 -2.20348487e-01  2.53665339e+00 -1.41183989e+00\n",
            " -2.20215199e+00 -2.57638575e+00 -3.62547149e+00 -3.28282428e+00\n",
            "  1.79807510e+00 -2.57367896e+00 -2.27318559e+00 -3.68421123e+00\n",
            " -2.10877103e+00  8.35159375e-01 -4.09093440e+00 -1.33229229e-01\n",
            "  2.30933632e+00 -2.91056898e+00 -7.08164555e-01 -9.70510264e-01\n",
            " -2.57753309e+00 -1.72052479e+00 -1.92017130e+00  1.87451338e+00\n",
            " -1.70802202e+00 -3.87468208e+00 -2.89130553e+00 -2.39829061e+00\n",
            " -2.93744698e+00 -1.11763261e+00 -2.02862775e+00 -3.11771312e+00\n",
            "  1.37477849e+00 -2.80381457e+00 -2.94703620e+00  1.31417413e+00\n",
            " -1.96987902e+00 -2.49139839e+00  5.13195234e-01  3.13139559e-03\n",
            " -4.19755554e+00 -4.57779300e+00  2.22266158e+00 -1.87108514e+00\n",
            " -3.29234096e+00 -1.92072766e+00 -3.14208587e+00  1.16353521e+00\n",
            "  2.05674532e+00  2.29938292e+00 -3.31820369e+00 -2.01336456e+00\n",
            " -1.76931547e+00 -3.09730062e+00 -2.42973232e+00 -2.37363945e+00\n",
            "  7.59349299e-01  2.20504104e+00 -1.82443661e+00  7.30876751e-01\n",
            "  1.58181446e+00  9.87862211e-01 -2.36975459e+00 -1.70141048e+00\n",
            " -2.45447742e+00 -2.63294865e+00 -2.45265723e+00  1.71016520e+00\n",
            " -2.83262366e+00  5.67815884e-01 -3.32008428e+00  1.40812372e+00\n",
            " -4.56289616e+00  1.63128329e+00 -3.72295666e+00  1.46894739e-01\n",
            " -3.14173930e+00 -1.60927315e+00 -2.23435186e+00 -3.25915651e+00\n",
            " -4.02935459e+00 -9.44307758e-01 -3.27304005e+00  4.96678907e-01\n",
            " -6.07831363e-01 -1.28584131e+00  1.51730101e+00 -2.44037473e-01\n",
            " -3.66206098e+00 -2.53692825e+00 -2.37582010e+00  1.87756920e+00\n",
            " -2.88700149e+00 -1.35028045e+00 -2.77388203e+00 -3.98673200e+00\n",
            " -1.91462688e+00 -2.01407780e+00 -2.88336174e+00 -1.14183084e+00\n",
            "  1.73355054e+00 -2.19874355e+00 -1.85301723e+00 -1.72319611e+00\n",
            " -1.06988631e+00 -1.93822837e+00 -1.48670867e+00  1.56047966e+00\n",
            " -3.85228527e+00 -3.24244821e+00 -2.28234233e+00 -2.91664534e+00\n",
            "  1.16072905e+00 -1.63025936e+00  1.55034265e+00 -3.09870698e+00\n",
            "  1.60862403e+00  9.07962356e-01 -2.71174940e+00 -1.71957554e+00\n",
            " -2.55953343e+00 -3.24411150e+00 -2.32806741e+00 -3.79383372e+00\n",
            " -2.88544428e+00 -3.09686387e+00  1.05721758e+00 -3.37445553e-01\n",
            " -3.36898133e+00  2.52725665e+00 -2.98923930e+00 -1.05481118e+00\n",
            " -3.27089135e+00  1.00521604e+00 -4.39934943e+00  1.68503848e+00\n",
            " -7.61915356e-01 -4.10263550e+00 -3.06348693e+00 -3.09094641e+00\n",
            "  4.24757460e-01 -1.68109714e+00 -2.78685593e+00 -1.57823547e+00\n",
            " -1.04840933e+00 -3.12940489e+00  2.07860176e+00  1.83632532e+00\n",
            " -4.50354181e-01 -2.68253359e+00 -2.16599227e+00 -3.07798868e+00\n",
            "  2.00504029e+00  1.35288442e+00  1.15620688e-01  1.09134336e+00\n",
            "  1.06921371e+00  3.96424097e-01  1.59180381e+00 -4.60243230e-01\n",
            "  1.48228450e+00 -2.17651101e+00 -9.69499023e-01 -3.94881835e+00\n",
            " -2.36172527e+00 -4.40966359e+00  1.55904457e+00 -1.69916480e+00\n",
            " -2.22108223e+00 -2.36628535e+00 -2.42697720e+00 -2.58100872e+00\n",
            " -2.68416838e+00 -2.87047509e+00  2.34625606e-01 -1.25766430e+00\n",
            " -2.71507606e+00 -2.52790822e+00 -1.41086373e+00  1.08232845e+00\n",
            " -2.54143355e+00 -3.73004472e+00  8.74975264e-01 -1.58207059e+00\n",
            " -8.03342550e-01 -2.92081038e+00 -2.08617106e+00 -1.44120423e+00\n",
            " -1.72030865e+00 -1.72719691e+00  6.78962086e-02 -8.07357961e-02\n",
            " -3.08306409e+00 -4.11173542e+00 -1.39311882e+00 -1.32079852e+00\n",
            "  1.41291840e+00 -1.37499192e+00  1.90639986e+00  2.08277015e+00\n",
            " -9.02352374e-01 -1.42069928e+00  1.34851441e+00 -7.89511971e-01\n",
            " -1.38415870e+00  1.00049594e+00  1.80110712e+00 -4.08048289e+00\n",
            " -7.36497395e-01 -2.95432418e+00 -2.95350137e+00  1.73845343e+00\n",
            " -2.51147003e+00 -3.60176095e+00 -2.02404590e+00 -4.46197107e-01\n",
            " -1.12745192e+00 -3.11327365e+00  4.98158707e-01  1.10409910e+00\n",
            " -2.32530790e+00  2.02560799e+00 -2.82883231e+00 -1.03108912e+00\n",
            " -2.27054349e+00  3.21538107e-01 -2.06848394e+00  5.84875229e-01\n",
            " -3.79777452e+00  2.50513834e+00 -8.31670018e-01 -4.35887114e+00\n",
            "  1.18078317e+00  2.23602442e+00 -2.64557837e+00 -5.85792985e-02\n",
            "  1.98681851e+00  2.67026302e-01 -3.27359230e+00 -3.06877081e+00\n",
            " -2.91647111e+00 -6.34839438e-01  4.33012545e+00 -9.36789451e-01\n",
            " -2.49319702e+00 -2.68435765e+00 -4.01184908e+00 -2.31341610e+00\n",
            " -2.31388032e+00 -3.16246389e+00 -2.76195833e+00 -3.99469376e+00\n",
            "  1.53524306e+00 -1.50816000e+00 -1.75832063e+00 -1.36623671e+00\n",
            " -1.14994100e-02 -3.44584880e-01 -3.93987001e+00  1.00267022e+00\n",
            " -2.58525358e+00  1.58319016e+00 -2.22703703e+00  1.89271068e+00\n",
            "  7.18173320e-01  2.56191489e-01 -2.02825301e+00  8.85037072e-01\n",
            " -2.69942864e+00  1.73258146e+00 -1.21544791e+00  1.06070169e+00\n",
            " -2.99240771e+00 -3.84568928e+00 -1.06446980e+00 -3.43605475e+00\n",
            " -3.85845095e+00 -2.97866594e+00 -3.01318781e+00 -1.02179122e+00\n",
            " -3.82483489e+00  1.70326383e+00  2.21210877e-01 -1.73094999e+00\n",
            "  3.07255609e+00 -2.10193709e+00 -1.74853822e+00 -2.74192387e+00\n",
            " -2.68566324e+00 -2.26321196e+00  2.34484945e+00 -2.36572691e+00\n",
            " -2.95305335e+00 -2.29083518e+00  1.36548319e+00  6.06414707e-01\n",
            " -3.38811555e+00 -1.27311664e+00 -2.35250617e-01 -1.56405591e+00\n",
            "  2.00129459e+00 -1.69516424e+00 -2.87160232e+00 -3.04541321e+00\n",
            "  2.30787463e+00 -1.88094930e+00 -1.53249305e+00 -2.36794983e+00\n",
            " -3.62512672e+00 -4.30832780e+00  1.92512048e+00 -2.42984730e+00\n",
            " -3.01441648e+00 -1.53696966e+00 -2.92195719e+00  3.75481498e-01\n",
            " -2.16876477e+00 -8.29591035e-01  1.45193868e+00  3.08683569e-02\n",
            "  1.50269477e+00 -3.56774476e+00 -2.18504559e-01  1.86650276e+00\n",
            "  1.43768199e+00 -2.40788069e+00 -2.29480860e+00 -3.36117467e+00\n",
            " -2.86707676e+00 -2.85634019e+00 -1.24879026e+00 -1.64367048e+00\n",
            " -3.38147983e+00  1.57910343e+00 -3.64501606e+00 -1.64127917e+00\n",
            " -2.42936393e+00 -3.58297971e+00  7.69629918e-01 -3.31661301e+00\n",
            " -3.54504691e+00 -2.55367668e+00 -2.30530018e+00  2.02803305e+00\n",
            " -5.89914825e-02  1.63739761e+00 -3.06818257e+00  1.86333306e+00\n",
            "  1.97341667e+00 -2.28567843e+00 -2.20221639e+00 -3.49303045e+00\n",
            "  1.64550713e+00 -9.63564230e-01 -2.50523207e+00 -3.69983510e+00\n",
            " -1.01099260e+00  7.92192465e-01 -2.58319513e+00 -2.85989306e+00\n",
            " -2.77136337e+00 -3.42857054e+00 -4.22298902e+00 -2.80033157e+00\n",
            " -3.78420111e+00  5.65566310e-01 -2.69564382e+00  1.94442396e+00\n",
            "  1.29983678e+00  3.76548104e-01 -3.38463929e+00  1.83347894e+00\n",
            " -8.72204876e-01 -2.79400154e+00  2.29605461e+00  1.82958291e+00\n",
            " -1.42171174e+00 -8.84759906e-01 -1.70761606e+00 -2.86848679e+00\n",
            " -3.15256567e+00 -2.67949442e+00 -1.62503839e+00 -1.91750827e+00\n",
            " -2.23511839e+00 -3.07384425e+00 -8.16654134e-01 -2.73426175e+00\n",
            " -1.71535010e+00 -3.00038734e+00  1.47334183e+00 -3.26684832e+00\n",
            " -2.15829940e+00 -4.22301093e+00 -1.03568322e+00  1.75526216e+00\n",
            " -2.44318917e+00 -1.61825678e+00 -2.97163540e+00 -1.62819976e+00\n",
            " -1.10811281e+00  1.74848159e+00 -1.28315396e+00 -3.65094016e+00\n",
            " -1.54198684e+00  2.89524576e+00 -1.34166517e+00 -1.32855916e+00\n",
            " -1.11241634e+00 -1.48080626e+00 -2.93866656e+00 -2.90996684e+00\n",
            " -2.53286917e+00 -2.02774535e+00 -5.71537944e-01 -2.04182462e+00\n",
            " -4.23573013e+00 -2.07439922e+00 -6.10400390e-01  1.13930636e+00\n",
            "  7.85623311e-01 -2.04357804e+00  4.72089805e-01 -3.29730804e+00\n",
            "  1.00728347e+00 -4.18568147e+00 -1.70109656e-01 -1.97809750e+00\n",
            " -3.66864354e-01 -4.88199952e-01 -1.78032271e+00 -3.85263581e+00\n",
            " -2.43742960e+00 -1.74697573e+00 -4.17153337e+00  1.63381435e+00\n",
            " -1.86561875e+00 -1.25944810e+00  1.44264860e+00 -2.13142745e+00\n",
            " -3.47307306e+00  1.51147675e+00 -3.06906021e+00  1.68959536e+00\n",
            "  5.01807762e-01 -1.12198957e+00 -1.99183844e+00 -3.50033645e+00\n",
            "  3.12801252e-01  2.41462917e+00  7.44483580e-01 -8.92996230e-01\n",
            "  1.27514400e+00 -3.27424020e+00 -2.48145187e+00  1.35013699e+00\n",
            "  8.60532282e-01 -1.22756301e+00 -4.03904725e+00  7.45298153e-01\n",
            " -9.09836846e-01 -2.40342331e+00  1.38174053e+00 -2.18450300e+00\n",
            " -1.56556763e+00  1.95776060e+00 -1.82838914e-01 -2.09644138e+00\n",
            " -4.78286204e-01  6.67780941e-01  1.25696389e+00 -2.52868546e-01\n",
            "  1.43240341e+00 -3.70779013e+00 -1.93281729e+00  7.66146422e-01\n",
            " -3.27577620e+00 -1.21784047e+00  4.25503550e+00  1.39820499e+00\n",
            " -3.09898900e+00  1.98069029e+00  1.13922761e+00 -3.29704140e+00\n",
            " -9.77928906e-01  1.30043951e+00 -2.05955161e+00 -9.58032127e-01\n",
            "  1.53738835e+00 -2.25227832e+00 -3.48954244e+00 -2.74199234e+00\n",
            "  1.83150586e+00 -2.84592728e+00 -1.92648529e+00 -2.95635100e+00\n",
            " -5.15238319e+00 -4.95902678e-01 -2.48029250e+00 -1.16377552e+00\n",
            " -1.65692352e+00 -2.33617984e+00 -2.84355323e+00 -4.17128813e+00\n",
            " -2.03800922e+00  1.60502314e+00 -2.99276009e+00  3.73721501e-01\n",
            "  1.31365581e+00 -3.27821318e+00 -1.64971829e+00 -3.26272077e+00\n",
            "  2.21365681e+00 -1.76457843e+00  1.88983510e+00 -3.93551984e+00\n",
            "  7.88466885e-01  3.86477386e-01 -2.09130221e+00 -2.08413221e+00\n",
            " -6.83352736e-01  1.37536637e+00  2.12330422e+00 -3.83477754e+00\n",
            " -2.95581143e+00 -1.30657161e-01  8.50434265e-01 -3.11670572e+00\n",
            " -1.29757522e+00  1.96664171e-01 -3.69644366e+00 -2.29357302e+00\n",
            " -3.67071355e+00 -3.00686454e+00 -1.24240131e+00 -9.09253342e-01\n",
            " -7.96821845e-01 -3.72315778e+00 -3.15569925e+00 -3.28711859e-01\n",
            " -2.72241966e+00 -2.62244915e+00  7.51558448e-02  5.48001570e-01\n",
            " -1.83176003e+00 -1.68622706e+00  2.33058999e+00 -2.75229526e+00\n",
            " -1.78290184e+00 -2.55984622e+00  2.11776014e+00 -2.47849109e+00\n",
            " -1.91602247e-01  3.70007352e-01 -2.73966009e+00 -1.81082257e+00\n",
            "  1.77604955e+00 -2.75647586e+00 -4.12934953e+00  8.02176535e-01\n",
            "  1.12937510e+00 -3.50681284e+00  1.47653110e+00 -3.40788293e+00\n",
            " -1.19332574e+00 -2.33203541e+00 -1.67465228e+00 -2.45561031e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0bKCboN4Zxu"
      },
      "source": [
        "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMn7OEN94Zxw"
      },
      "source": [
        "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
        "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0n5EFkx4Zxz"
      },
      "source": [
        "## TASK F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0HOqVJq4Zx1"
      },
      "source": [
        "\n",
        "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
        "\n",
        "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
        "\n",
        "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
        "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
        "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
        "\n",
        "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTY7z2bd4Zx2"
      },
      "source": [
        "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM3odN1Z4Zx3"
      },
      "source": [
        "\n",
        "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
        "\n",
        "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
        "\n",
        "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
        "\n",
        "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
        "\n",
        "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0duDtHdnkozS"
      },
      "source": [
        "#First of the first lets calculate the Y+ and Y- based on Y_Train:\n",
        "N_positive, N_negative = np.unique(Y_Train,return_counts=True)[1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeKjvC8_kouW",
        "outputId": "177c9f04-c313-422f-ee07-6a5b0a454a6d"
      },
      "source": [
        "print(N_negative)\n",
        "print(N_positive)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1211\n",
            "2789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_q9kTVkkoo6"
      },
      "source": [
        "Y_positive = (N_positive+1)/(N_positive+2)\n",
        "Y_negative = 1/(N_negative+2)\n",
        "Y_CV_New = []\n",
        "for points in Y_cv:\n",
        "    if points == 0:\n",
        "        Y_CV_New.append(Y_negative)\n",
        "    else:\n",
        "        Y_CV_New.append(Y_positive)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzKUtWOvlh6T"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    w = np.zeros_like(dim).reshape(1,-1)\n",
        "    b = 0\n",
        "\n",
        "    return w,b\n",
        "\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    result = 1/(1+np.exp(-z))\n",
        "    return result\n",
        "\n",
        "def log_loss(w,b,X,Y):\n",
        "    N = len(X)\n",
        "    sum_log = 0\n",
        "    for i in range(N):\n",
        "        sum_log += (Y[i]*np.log10(sigmoid(X[i]))) + ((1-Y[i])*np.log10(1-sigmoid(X[i])))\n",
        "        return -1*sum_log/N\n",
        "\n",
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw = (x * (y- sigmoid((w@x)+b) )) - ((alpha/N)*w)\n",
        "    return dw\n",
        "\n",
        "def gradient_db(x,y,w,b):\n",
        "    '''In this function, we will compute gradient w.r.to b '''\n",
        "    db = y - sigmoid(w@x+b)\n",
        "    return db\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(X_train,y_train,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    train_loss= []\n",
        "    w,b = initialize_weights(X_train[0])\n",
        "    #print(\"weight is {}\".format(b))\n",
        "\n",
        "    N = len(X_train)\n",
        "    for epoch in tqdm(range(0,epochs)):\n",
        "        for x,y in zip(X_train.reshape(-1,1),y_train.reshape(-1,1)):\n",
        "            #print(x.shape)\n",
        "            #print(y.shape)\n",
        "            #print(w.shape)\n",
        "            #print(b)\n",
        "            gradw = gradient_dw(x,y,w,b,alpha,N)\n",
        "            gradb = gradient_db(x,y,w,b)\n",
        "            w += (eta0 * gradw)\n",
        "            b += (eta0 * gradb)\n",
        "       \n",
        "        trainloss = log_loss(y_train, 1/(1+np.exp(-(w * decision_function(X_train) + b))),x,y) \n",
        "        train_loss.append(trainloss)\n",
        "        print(f\"Epoch {epoch+1}: Training loss: {trainloss}\")\n",
        "                \n",
        "    return w,b"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiKNZ7OzkoY1",
        "outputId": "23b8933b-574a-42d1-f07a-cd3858a66510"
      },
      "source": [
        "w, b = train(F_cv,np.array(Y_CV_New), 50, 0.0001, 0.0001)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:07<05:44,  7.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 2/50 [00:14<05:36,  7.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 3/50 [00:21<05:33,  7.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 4/50 [00:28<05:29,  7.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 5/50 [00:35<05:23,  7.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 6/50 [00:43<05:19,  7.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 7/50 [00:50<05:05,  7.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 8/50 [00:56<04:53,  6.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 9/50 [01:03<04:47,  7.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 10/50 [01:11<04:42,  7.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 11/50 [01:17<04:31,  6.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 12/50 [01:24<04:23,  6.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 13/50 [01:31<04:17,  6.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 14/50 [01:38<04:13,  7.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 15/50 [01:45<04:06,  7.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 16/50 [01:52<03:56,  6.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 17/50 [01:59<03:48,  6.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 18/50 [02:06<03:42,  6.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 19/50 [02:13<03:32,  6.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 20/50 [02:20<03:28,  6.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 21/50 [02:27<03:21,  6.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 22/50 [02:34<03:15,  6.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 23/50 [02:40<03:04,  6.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 24/50 [02:47<02:58,  6.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 25/50 [02:55<02:55,  7.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 26/50 [03:02<02:50,  7.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 26: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 27/50 [03:09<02:43,  7.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 28/50 [03:16<02:37,  7.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 29/50 [03:23<02:29,  7.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 30/50 [03:30<02:21,  7.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 31/50 [03:38<02:14,  7.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 31: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 32/50 [03:45<02:08,  7.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 32: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 33/50 [03:52<02:02,  7.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 33: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 34/50 [03:59<01:52,  7.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 35/50 [04:06<01:44,  6.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 35: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 36/50 [04:12<01:36,  6.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 36: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 37/50 [04:19<01:29,  6.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 38/50 [04:26<01:24,  7.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 39/50 [04:33<01:17,  7.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 40/50 [04:41<01:10,  7.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 40: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 41/50 [04:48<01:03,  7.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 41: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 42/50 [04:55<00:56,  7.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 43/50 [05:02<00:49,  7.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 44/50 [05:09<00:41,  6.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 45/50 [05:15<00:34,  6.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 46/50 [05:22<00:27,  6.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 47/50 [05:29<00:20,  6.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 48/50 [05:36<00:13,  6.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 49/50 [05:43<00:06,  6.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [05:50<00:00,  7.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50: Training loss: 0.036633350822519145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59-CmhEykoTg",
        "outputId": "ba961cb3-cc03-4d41-eb7d-5c02bbb69ccb"
      },
      "source": [
        "print(w.shape)\n",
        "print(b.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1)\n",
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJesQIOJkoN9"
      },
      "source": [
        "w = w.flatten()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVFOLXSpkoIT",
        "outputId": "25d24832-7e61-4848-ce83-d972b787719e"
      },
      "source": [
        "w.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CPhQba-koDH"
      },
      "source": [
        "z=(w * decision_function(X_test) + b)\n",
        "result = sigmoid(z)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83_mhFtukn8S",
        "outputId": "0966f6e3-e919-4643-9e80-f69b74b015c5"
      },
      "source": [
        "predict = []\n",
        "\n",
        "for i in result:\n",
        "    if i >=0.5:\n",
        "        predict.append(1)\n",
        "    else:\n",
        "        predict.append(0)\n",
        "print(np.array(predict))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0\n",
            " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0\n",
            " 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
            " 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0\n",
            " 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0\n",
            " 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1 1\n",
            " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
            " 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0\n",
            " 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
            " 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0\n",
            " 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
            " 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0\n",
            " 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 1\n",
            " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
            " 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0\n",
            " 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0\n",
            " 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTJLiQ-lveMp",
        "outputId": "81365bed-553a-4b5c-9db1-fa79434d7377"
      },
      "source": [
        "print(1-np.sum(Y_test  - predict)/len(X_test))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.977\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}